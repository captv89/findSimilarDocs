{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-02 23:11:56.137900: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "from pymilvus import CollectionSchema, FieldSchema, DataType, Collection, utility, connections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Connect to Milvus server\n",
    "connections.connect(\n",
    "  alias=\"default\",\n",
    "  user='username',\n",
    "  password='password',\n",
    "  host='localhost',\n",
    "  port='19530'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define PrimaryKey field\n",
    "primary_field = FieldSchema(name=\"id\", dtype=DataType.INT64, is_primary=True, auto_id=True)\n",
    "\n",
    "# Define field schema for document vectors\n",
    "doc_name_field = FieldSchema(name=\"document_name\", dtype=DataType.VARCHAR, max_length=200,\n",
    "  # The default value will be used if this field is left empty during data inserts or upserts.\n",
    "  # The data type of `default_value` must be the same as that specified in `dtype`.\n",
    "  default_value=\"Unknown\")\n",
    "doc_vector_field = FieldSchema(name=\"document_vectors\", dtype=DataType.FLOAT_VECTOR, dim=512)\n",
    "\n",
    "# Create a collection schema\n",
    "schema = CollectionSchema(fields=[primary_field, doc_name_field, doc_vector_field], description=\"Collection for storing document vectors\")\n",
    "\n",
    "# Specify collection parameters\n",
    "collection_name = \"document_embeddings\"\n",
    "shards_num = 2\n",
    "\n",
    "# Create a collection\n",
    "collection = Collection(name=collection_name, schema=schema, using='default', shards_num=shards_num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load model\n",
    "# From modal available locally\n",
    "model_path = 'universal-sentence-encoder_4'\n",
    "model = hub.load(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def embed(input):\n",
    "    return model(input)\n",
    "\n",
    "def embed_and_add_to_collection(document_data, collection_name):\n",
    "    collection = Collection(collection_name)\n",
    "    embeddings = embed([content for _, content in document_data])\n",
    "    \n",
    "    # Convert embeddings to list\n",
    "    vectors = [embedding.numpy().tolist() for embedding in embeddings]\n",
    "    \n",
    "    # Get document names\n",
    "    doc_names = [doc_name for doc_name, _ in document_data]\n",
    "    \n",
    "    data = [\n",
    "        doc_names,\n",
    "        vectors\n",
    "    ]\n",
    "\n",
    "    status = collection.insert(data)\n",
    "    print(status)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load collection of word documents along with their names\n",
    "document_data = [\n",
    "    ('document1.txt', open('document1.txt').read()),\n",
    "    ('document2.txt', open('document2.txt').read()),\n",
    "    ('document3.txt', open('document3.txt').read()),\n",
    "    ('document4.txt', open('document4.txt').read()),\n",
    "    ('document5.txt', open('document5.txt').read()),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(insert count: 5, delete count: 0, upsert count: 0, timestamp: 446754647392911366, success count: 5, err count: 0)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Represent documents as vectors\n",
    "\n",
    "# Embed each document in the collection\n",
    "embed_and_add_to_collection(document_data, collection_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_rows': 0, 'indexed_rows': 0, 'pending_index_rows': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build Index\n",
    "index_params = {\n",
    "  \"metric_type\":\"COSINE\",\n",
    "  \"index_type\":\"IVF_FLAT\",\n",
    "  \"params\":{\n",
    "    \"nlist\": 2048\n",
    "  }\n",
    "}\n",
    "\n",
    "# Get an existing collection.\n",
    "collection = Collection(collection_name)      \n",
    "collection.create_index(\n",
    "  field_name=\"document_vectors\", \n",
    "  index_params=index_params\n",
    ")\n",
    "\n",
    "utility.index_building_progress(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load target document\n",
    "target_document = open('document3.txt').read()\n",
    "\n",
    "# Embed target document\n",
    "target_document_embedding = embed([target_document])[0]\n",
    "\n",
    "# Convert to numpy array\n",
    "target_document_list = [target_document_embedding.numpy().tolist()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Search for similar documents\n",
    "top_k = 5\n",
    "search_param = {\n",
    "    'nprobe': 16\n",
    "}\n",
    "\n",
    "# Search in collection\n",
    "collection = Collection(collection_name)\n",
    "collection.load()\n",
    "\n",
    "# Prepare search parameters\n",
    "search_params = {\n",
    "    \"metric_type\": \"COSINE\",\n",
    "    \"params\": {\"nprobe\": 16}\n",
    "}\n",
    "\n",
    "results = collection.search(data=target_document_list, \n",
    "                            anns_field=\"document_vectors\", \n",
    "                            param=search_params, \n",
    "                            limit=top_k, \n",
    "                            expr=None, \n",
    "                            output_fields=['document_name'], \n",
    "                            consistency_level=\"Strong\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document name: document3.txt, Distance: 1.000000238418579\n"
     ]
    }
   ],
   "source": [
    "# Get top hit\n",
    "hit = results[0][0]\n",
    "\n",
    "\n",
    "# Print the top 1 hit document name and distance\n",
    "print(f\"Document name: {hit.entity.get('document_name')}, Distance: {hit.distance}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document Name: document3.txt, Distance: 1.000000238418579, Similarity: 100.0 %\n",
      "Document Name: document5.txt, Distance: 0.1426936239004135, Similarity: 14.27 %\n",
      "Document Name: document4.txt, Distance: 0.137556254863739, Similarity: 13.76 %\n",
      "Document Name: document1.txt, Distance: 0.10334134101867676, Similarity: 10.33 %\n",
      "Document Name: document2.txt, Distance: 0.04267469048500061, Similarity: 4.27 %\n"
     ]
    }
   ],
   "source": [
    "# Assuming 'result' is of type pymilvus.client.abstract.Hits\n",
    "hits = results[0]  # Assuming the hits are in the first element of the Hits object\n",
    "\n",
    "# Iterate through the hits and print document names and distances\n",
    "for hit in hits:\n",
    "    document_name = hit.entity.get('document_name')\n",
    "    distance = hit.distance\n",
    "    sim_percent = round(distance * 100, 2)\n",
    "    print(f\"Document Name: {document_name}, Distance: {distance}, Similarity: {sim_percent} %\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
