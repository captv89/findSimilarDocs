{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: transformers<5.0.0,>=4.6.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (4.36.2)\n",
      "Requirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (4.66.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: torchvision in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (0.16.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (1.26.2)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: nltk in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (3.8.1)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp311-cp311-macosx_10_9_x86_64.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in ./.venv/lib/python3.11/site-packages (from sentence-transformers) (0.20.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.12.2)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in ./.venv/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.venv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: click in ./.venv/lib/python3.11/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in ./.venv/lib/python3.11/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in ./.venv/lib/python3.11/site-packages (from torchvision->sentence-transformers) (10.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=54695ebff8be4c47ad95fe06f9d5cf11f4f9f19e4f82ef2868d987649d8d7c85\n",
      "  Stored in directory: /Users/scorpion/Library/Caches/pip/wheels/c5/ca/33/8657d5aded943d57e56bf40ec332c8960f9f3f70a143e34731\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, sentence-transformers\n",
      "Successfully installed sentence-transformers-2.2.2 sentencepiece-0.1.99\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 6.76569045e-02  6.34959936e-02  4.87131141e-02  7.93049857e-02\n",
      "   3.74480560e-02  2.65282183e-03  3.93749513e-02 -7.09848432e-03\n",
      "   5.93614392e-02  3.15370262e-02  6.00980893e-02 -5.29052615e-02\n",
      "   4.06067967e-02 -2.59308796e-02  2.98428107e-02  1.12691545e-03\n",
      "   7.35148564e-02 -5.03818206e-02 -1.22386590e-01  2.37028450e-02\n",
      "   2.97265183e-02  4.24769111e-02  2.56337244e-02  1.99516746e-03\n",
      "  -5.69190830e-02 -2.71597821e-02 -3.29035372e-02  6.60249069e-02\n",
      "   1.19007193e-01 -4.58791442e-02 -7.26214424e-02 -3.25840078e-02\n",
      "   5.23413792e-02  4.50553335e-02  8.25304259e-03  3.67023759e-02\n",
      "  -1.39415041e-02  6.53918907e-02 -2.64272299e-02  2.06426121e-04\n",
      "  -1.36643676e-02 -3.62810642e-02 -1.95044167e-02 -2.89737936e-02\n",
      "   3.94270308e-02 -8.84091109e-02  2.62424489e-03  1.36713097e-02\n",
      "   4.83062975e-02 -3.11566256e-02 -1.17329188e-01 -5.11690341e-02\n",
      "  -8.85287672e-02 -2.18963344e-02  1.42986523e-02  4.44168299e-02\n",
      "  -1.34815611e-02  7.43392259e-02  2.66382992e-02 -1.98762473e-02\n",
      "   1.79191455e-02 -1.06052039e-02 -9.04262662e-02  2.13269107e-02\n",
      "   1.41204879e-01 -6.47172704e-03 -1.40379486e-03 -1.53609617e-02\n",
      "  -8.73572305e-02  7.22174197e-02  2.01402456e-02  4.25588116e-02\n",
      "  -3.49013694e-02  3.19459563e-04 -8.02970678e-02 -3.27471793e-02\n",
      "   2.85268556e-02 -5.13657928e-02  1.09389193e-01  8.19327608e-02\n",
      "  -9.84039977e-02 -9.34095979e-02 -1.51292579e-02  4.51248735e-02\n",
      "   4.94171754e-02 -2.51868200e-02  1.57077741e-02 -1.29290715e-01\n",
      "   5.31892199e-03  4.02341783e-03 -2.34571882e-02 -6.72982931e-02\n",
      "   2.92280130e-02 -2.60844827e-02  1.30624697e-02 -3.11663188e-02\n",
      "  -4.82714251e-02 -5.58859408e-02 -3.87505218e-02  1.20010845e-01\n",
      "  -1.03924274e-02  4.89704832e-02  5.53537160e-02  4.49358560e-02\n",
      "  -4.00978327e-03 -1.02959767e-01 -2.92968731e-02 -5.83402440e-02\n",
      "   2.70472299e-02 -2.20168959e-02 -7.22241476e-02 -4.13869955e-02\n",
      "  -1.93297509e-02  2.73328763e-03  2.76981591e-04 -9.67588574e-02\n",
      "  -1.00574687e-01 -1.41923297e-02 -8.07891786e-02  4.53925394e-02\n",
      "   2.45041419e-02  5.97613975e-02 -7.38184899e-02  1.19844079e-02\n",
      "  -6.63403645e-02 -7.69045502e-02  3.85157838e-02 -5.59362183e-33\n",
      "   2.80013438e-02 -5.60785159e-02 -4.86601926e-02  2.15569306e-02\n",
      "   6.01980835e-02 -4.81402390e-02 -3.50246839e-02  1.93314105e-02\n",
      "  -1.75152402e-02 -3.89211290e-02 -3.81069118e-03 -1.70287676e-02\n",
      "   2.82099862e-02  1.28290560e-02  4.71600778e-02  6.21030293e-02\n",
      "  -6.43588752e-02  1.29285619e-01 -1.31230997e-02  5.23069389e-02\n",
      "  -3.73680666e-02  2.89094578e-02 -1.68981347e-02 -2.37330515e-02\n",
      "  -3.33492048e-02 -5.16762771e-02  1.55356480e-02  2.08802968e-02\n",
      "  -1.25372047e-02  4.59578708e-02  3.72719616e-02  2.80566830e-02\n",
      "  -5.90004735e-02 -1.16988476e-02  4.92182635e-02  4.70328405e-02\n",
      "   7.35487640e-02 -3.70529927e-02  3.98455746e-03  1.06411902e-02\n",
      "  -1.61499251e-04 -5.27165644e-02  2.75927782e-02 -3.92921455e-02\n",
      "   8.44717622e-02  4.86861095e-02 -4.85875411e-03  1.79948770e-02\n",
      "  -4.28569093e-02  1.23375058e-02  6.39952440e-03  4.04823460e-02\n",
      "   1.48887318e-02 -1.53941130e-02  7.62948766e-02  2.37043928e-02\n",
      "   4.45236750e-02  5.08195758e-02 -2.31255032e-03 -1.88737046e-02\n",
      "  -1.23336064e-02  4.66001667e-02 -5.63438274e-02  6.29927367e-02\n",
      "  -3.15535292e-02  3.24912481e-02  2.34673731e-02 -6.55438527e-02\n",
      "   2.01709531e-02  2.57082749e-02 -1.23869190e-02 -8.36492330e-03\n",
      "  -6.64377660e-02  9.43074003e-02 -3.57092880e-02 -3.42483036e-02\n",
      "  -6.66357158e-03 -8.01523589e-03 -3.09711099e-02  4.33012396e-02\n",
      "  -8.21403787e-03 -1.50795028e-01  3.07691637e-02  4.00719158e-02\n",
      "  -3.79293859e-02  1.93214579e-03  4.00530845e-02 -8.77075270e-02\n",
      "  -3.68490741e-02  8.57961271e-03 -3.19251791e-02 -1.25257866e-02\n",
      "   7.35539719e-02  1.34734914e-03  2.05918383e-02  2.71098017e-33\n",
      "  -5.18576838e-02  5.78361228e-02 -9.18985307e-02  3.94421406e-02\n",
      "   1.05576538e-01 -1.96911916e-02  6.18402325e-02 -7.63465390e-02\n",
      "   2.40880381e-02  9.40049142e-02 -1.16535477e-01  3.71198803e-02\n",
      "   5.22425026e-02 -3.95857543e-03  5.72214723e-02  5.32849133e-03\n",
      "   1.24016829e-01  1.39022777e-02 -1.10250497e-02  3.56053039e-02\n",
      "  -3.30754891e-02  8.16574767e-02 -1.52003635e-02  6.05585463e-02\n",
      "  -6.01397417e-02  3.26102749e-02 -3.48296426e-02 -1.69881750e-02\n",
      "  -9.74907130e-02 -2.71483865e-02  1.74708723e-03 -7.68981948e-02\n",
      "  -4.31858115e-02 -1.89985279e-02 -2.91660875e-02  5.77487573e-02\n",
      "   2.41821986e-02 -1.16902469e-02 -6.21435195e-02  2.84351744e-02\n",
      "  -2.37523855e-04 -2.51783300e-02  4.39638039e-03  8.12840089e-02\n",
      "   3.64184342e-02 -6.04006350e-02 -3.65517586e-02 -7.93748721e-02\n",
      "  -5.08528948e-03  6.69698864e-02 -1.17784321e-01  3.23743336e-02\n",
      "  -4.71252538e-02 -1.34459203e-02 -9.48444977e-02  8.24956223e-03\n",
      "  -1.06748492e-02 -6.81881830e-02  1.11815182e-03  2.48019975e-02\n",
      "  -6.35889098e-02  2.84493007e-02 -2.61303745e-02  8.58111605e-02\n",
      "   1.14682287e-01 -5.35345785e-02 -5.63588738e-02  4.26009186e-02\n",
      "   1.09454868e-02  2.09578499e-02  1.00131057e-01  3.26050632e-02\n",
      "  -1.84208795e-01 -3.93208228e-02 -6.91454932e-02 -6.38104603e-02\n",
      "  -6.56386167e-02 -6.41253823e-03 -4.79612313e-02 -7.68133178e-02\n",
      "   2.95384321e-02 -2.29948238e-02  4.17036861e-02 -2.50047706e-02\n",
      "  -4.54508234e-03 -4.17136624e-02 -1.32289296e-02 -6.38357401e-02\n",
      "  -2.46472727e-03 -1.37337549e-02  1.68976579e-02 -6.30398393e-02\n",
      "   8.98880661e-02  4.18171175e-02 -1.85687691e-02 -1.80442168e-08\n",
      "  -1.67998075e-02 -3.21577303e-02  6.30383566e-02 -4.13091742e-02\n",
      "   4.44819070e-02  2.02466780e-03  6.29592314e-02 -5.17371949e-03\n",
      "  -1.00444369e-02 -3.05639580e-02  3.52673084e-02  5.58581464e-02\n",
      "  -4.67124693e-02  3.45102735e-02  3.29578035e-02  4.30114307e-02\n",
      "   2.94360910e-02 -3.03164665e-02 -1.71107464e-02  7.37484619e-02\n",
      "  -5.47910258e-02  2.77515221e-02  6.20169006e-03  1.58800241e-02\n",
      "   3.42978612e-02 -5.15750423e-03  2.35080309e-02  7.53135532e-02\n",
      "   1.92842968e-02  3.36197354e-02  5.09103723e-02  1.52497083e-01\n",
      "   1.64207611e-02  2.70528141e-02  3.75162400e-02  2.18553152e-02\n",
      "   5.66333942e-02 -3.95746380e-02  7.12313503e-02 -5.41377328e-02\n",
      "   1.03771058e-03  2.11853087e-02 -3.56309228e-02  1.09016962e-01\n",
      "   2.76531628e-03  3.13997269e-02  1.38421985e-03 -3.45737971e-02\n",
      "  -4.59277742e-02  2.88083088e-02  7.16904551e-03  4.84684557e-02\n",
      "   2.61018481e-02 -9.44064651e-03  2.82169245e-02  3.48724164e-02\n",
      "   3.69098634e-02 -8.58952850e-03 -3.53205428e-02 -2.47857366e-02\n",
      "  -1.91921294e-02  3.80707607e-02  5.99653125e-02 -4.22287248e-02]\n",
      " [ 8.64386335e-02  1.02762640e-01  5.39457100e-03  2.04439601e-03\n",
      "  -9.96336713e-03  2.53855269e-02  4.92875353e-02 -3.06265857e-02\n",
      "   6.87255114e-02  1.01366015e-02  7.75397792e-02 -9.00807455e-02\n",
      "   6.10616850e-03 -5.69898784e-02  1.41714783e-02  2.80491747e-02\n",
      "  -8.68464708e-02  7.64398724e-02 -1.03491351e-01 -6.77437931e-02\n",
      "   6.99946731e-02  8.44251066e-02 -7.24911457e-03  1.04770279e-02\n",
      "   1.34021007e-02  6.77577183e-02 -9.42085907e-02 -3.71690132e-02\n",
      "   5.22617511e-02 -3.10853459e-02 -9.63407084e-02  1.57717019e-02\n",
      "   2.57866811e-02  7.85245076e-02  7.89949074e-02  1.91516262e-02\n",
      "   1.64356399e-02  3.10085295e-03  3.81311513e-02  2.37090625e-02\n",
      "   1.05389757e-02 -4.40645255e-02  4.41738777e-02 -2.58728135e-02\n",
      "   6.15378395e-02 -4.05427627e-02 -8.64140019e-02  3.19722630e-02\n",
      "  -8.90694442e-04 -2.44437475e-02 -9.19721350e-02  2.33939402e-02\n",
      "  -8.30293372e-02  4.41510454e-02 -2.49692984e-02  6.23020232e-02\n",
      "  -1.30352331e-03  7.51395822e-02  2.46384721e-02 -6.47244453e-02\n",
      "  -1.17727771e-01  3.83392163e-02 -9.11766961e-02  6.35446087e-02\n",
      "   7.62739629e-02 -8.80241245e-02  9.54558048e-03 -4.69717830e-02\n",
      "  -8.41740966e-02  3.88823561e-02 -1.14393555e-01  6.28857082e-03\n",
      "  -3.49361822e-02  2.39750538e-02 -3.31317037e-02 -1.57243926e-02\n",
      "  -3.78955491e-02 -8.81249458e-03  7.06119090e-02  3.28066424e-02\n",
      "   2.03672820e-03 -1.12278990e-01  6.79719867e-03  1.22765685e-02\n",
      "   3.35303210e-02 -1.36200553e-02 -2.25489903e-02 -2.25229040e-02\n",
      "  -2.03194991e-02  5.04297763e-02 -7.48652667e-02 -8.22822452e-02\n",
      "   7.65962377e-02  4.93392050e-02 -3.75553444e-02  1.44634601e-02\n",
      "  -5.72458096e-02 -1.79954022e-02  1.09697931e-01  1.19462796e-01\n",
      "   8.09265999e-04  6.17057383e-02  3.26322392e-02 -1.30780056e-01\n",
      "  -1.48636669e-01 -6.16232827e-02  4.33886275e-02  2.67129205e-02\n",
      "   1.39786340e-02 -3.94002348e-02 -2.52712071e-02  3.87739181e-03\n",
      "   3.58664542e-02 -6.15420975e-02  3.76660563e-02  2.67565176e-02\n",
      "  -3.82659175e-02 -3.54793333e-02 -2.39227582e-02  8.67977366e-02\n",
      "  -1.84063390e-02  7.71039575e-02  1.39863102e-03  7.00383335e-02\n",
      "  -4.77877893e-02 -7.89820030e-02  5.10814376e-02 -2.99868315e-33\n",
      "  -3.91646177e-02 -2.56210566e-03  1.65210459e-02  9.48936120e-03\n",
      "  -5.66219352e-02  6.57783300e-02 -4.77002561e-02  1.11662028e-02\n",
      "  -5.73558547e-02 -9.16260295e-03 -2.17520948e-02 -5.59531860e-02\n",
      "  -1.11422716e-02  9.32793245e-02  1.66765228e-02 -1.36723537e-02\n",
      "   4.34388630e-02  1.87240343e-03  7.29949214e-03  5.16331680e-02\n",
      "   4.80608605e-02  1.35341465e-01 -1.71739254e-02 -1.29698301e-02\n",
      "  -7.50110298e-02  2.61107814e-02  2.69802082e-02  7.83023308e-04\n",
      "  -4.87270169e-02  1.17842667e-02 -4.59580906e-02 -4.83213402e-02\n",
      "  -1.95671022e-02  1.93889439e-02  1.98807530e-02  1.67432241e-02\n",
      "   9.87801403e-02 -2.74087936e-02  2.34809015e-02  3.70230805e-03\n",
      "  -6.14514686e-02 -1.21227710e-03 -9.50472988e-03  9.25155822e-03\n",
      "   2.38444172e-02  8.61232132e-02  2.26789694e-02  5.45126037e-04\n",
      "   3.47129367e-02  6.25464693e-03 -6.92776684e-03  3.92400734e-02\n",
      "   1.15675237e-02  3.26280072e-02  6.22155517e-02  2.76114736e-02\n",
      "   1.86883733e-02  3.55805941e-02  4.11795937e-02  1.54782226e-02\n",
      "   4.22691554e-02  3.82248387e-02  1.00313509e-02 -2.83246078e-02\n",
      "   4.47052456e-02 -4.10458632e-02 -4.50548530e-03 -5.44734299e-02\n",
      "   2.62320768e-02  1.79862808e-02 -1.23118781e-01 -4.66951840e-02\n",
      "  -1.35913305e-02  6.46710694e-02  3.57346283e-03 -1.22234067e-02\n",
      "  -1.79382302e-02 -2.55502090e-02  2.37224158e-02  4.08666860e-03\n",
      "  -6.51476085e-02  4.43651490e-02  4.68596257e-02 -3.25174816e-02\n",
      "   4.02267184e-03 -3.97606520e-03  1.11939432e-02 -9.95597988e-02\n",
      "   3.33168581e-02  8.01061019e-02  9.42692533e-02 -6.38293922e-02\n",
      "   3.23151648e-02 -5.13553545e-02 -7.49876536e-03  5.30047622e-34\n",
      "  -4.13194969e-02  9.49647129e-02 -1.06401429e-01  4.96590696e-02\n",
      "  -3.41913216e-02 -3.16745974e-02 -1.71556007e-02  1.70104450e-03\n",
      "   5.79757988e-02 -1.21777714e-03 -1.68536268e-02 -5.16912751e-02\n",
      "   5.52998707e-02 -3.42648067e-02  3.08179371e-02 -3.10481209e-02\n",
      "   9.27532837e-02  3.72663997e-02 -2.37398334e-02  4.45893444e-02\n",
      "   1.46153346e-02  1.16239391e-01 -5.00112735e-02  3.88716720e-02\n",
      "   4.24747309e-03  2.56976523e-02  3.27243917e-02  4.29907627e-02\n",
      "  -1.36144580e-02  2.56122462e-02  1.06262313e-02 -8.46863762e-02\n",
      "  -9.52982530e-02  1.08399898e-01 -7.51600042e-02 -1.37773622e-02\n",
      "   6.37338161e-02 -4.49668895e-03 -3.25321741e-02  6.23613670e-02\n",
      "   3.48053090e-02 -3.54922377e-02 -2.00222693e-02  3.66608389e-02\n",
      "  -2.48837080e-02  1.01818629e-02 -7.01233223e-02 -4.31950800e-02\n",
      "   2.95332707e-02 -2.94911501e-04 -3.45386751e-02  1.46675808e-02\n",
      "  -9.83969942e-02 -4.70488183e-02 -8.85495078e-03 -8.89914259e-02\n",
      "   3.50995921e-02 -1.29602000e-01 -4.98866290e-02 -6.12047277e-02\n",
      "  -5.97797446e-02  9.46319662e-03  4.91218008e-02 -7.75026903e-02\n",
      "   8.09727162e-02 -4.79257517e-02  2.34378991e-03  7.57031590e-02\n",
      "  -2.40175463e-02 -1.52546028e-02  4.86738682e-02 -3.85968573e-02\n",
      "  -7.04831555e-02 -1.20348241e-02 -3.88790816e-02 -7.76017532e-02\n",
      "  -1.07243927e-02  1.04188304e-02 -2.13753637e-02 -9.17386413e-02\n",
      "  -1.11344820e-02 -2.96066273e-02  2.46458482e-02  4.65713209e-03\n",
      "  -1.63449850e-02 -3.95219512e-02  7.73373321e-02 -2.84732841e-02\n",
      "  -3.69939720e-03  8.27665329e-02 -1.10409111e-02  3.13983299e-02\n",
      "   5.35094216e-02  5.75146042e-02 -3.17622200e-02 -1.52911284e-08\n",
      "  -7.99661204e-02 -4.76797260e-02 -8.59789103e-02  5.69616482e-02\n",
      "  -4.08866517e-02  2.23832559e-02 -4.64448053e-03 -3.80130634e-02\n",
      "  -3.10671143e-02 -1.07277827e-02  1.97698381e-02  7.77000654e-03\n",
      "  -6.09473605e-03 -3.86376232e-02  2.80271992e-02  6.78137764e-02\n",
      "  -2.35351492e-02  3.21747251e-02  8.02538730e-03 -2.39106677e-02\n",
      "  -1.21996074e-03  3.14599164e-02 -5.24924360e-02 -8.06816481e-03\n",
      "   3.14773154e-03  5.11496589e-02 -4.44104634e-02  6.36013448e-02\n",
      "   3.85084040e-02  3.30433138e-02 -4.18725563e-03  4.95592766e-02\n",
      "  -5.69605269e-02 -6.49712095e-03 -2.49793120e-02 -1.60867292e-02\n",
      "   6.62289709e-02 -2.06310768e-02  1.08045749e-01  1.68547146e-02\n",
      "   1.43812858e-02 -1.32127367e-02 -1.29387394e-01  6.95216730e-02\n",
      "  -5.55773079e-02 -6.75413162e-02 -5.45818498e-03 -6.13593822e-03\n",
      "   3.90840955e-02 -6.28779605e-02  3.74063514e-02 -1.16570657e-02\n",
      "   1.29150273e-02 -5.52495345e-02  5.16075902e-02 -4.30839183e-03\n",
      "   5.80247603e-02  1.86945051e-02  2.27810461e-02  3.21665443e-02\n",
      "   5.37979119e-02  7.02849030e-02  7.49312192e-02 -8.41775015e-02]]\n",
      "tensor([[0.7046, 0.4360]])\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "embeddings = model.encode(sentences)\n",
    "print(embeddings)\n",
    "\n",
    "testSentence = \"This is a test sentence\"\n",
    "\n",
    "#Compute embedding for both lists\n",
    "testSentence_embedding = model.encode(testSentence)\n",
    "\n",
    "#Compute cosine-similarits\n",
    "cos_sim  = util.cos_sim(testSentence_embedding, embeddings)\n",
    "\n",
    "#Output the result\n",
    "print(cos_sim)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'A man is riding a horse.',\n",
    "          'A woman is playing violin.',\n",
    "          'Two men pushed carts through the woods.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.'\n",
    "          ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-5 most similar pairs:\n",
      "A man is eating food. \t A man is eating a piece of bread. \t 0.7553\n",
      "A man is riding a horse. \t A man is riding a white horse on an enclosed ground. \t 0.7369\n",
      "A monkey is playing drums. \t Someone in a gorilla costume is playing a set of drums. \t 0.6433\n",
      "A woman is playing violin. \t Someone in a gorilla costume is playing a set of drums. \t 0.2564\n",
      "A man is eating food. \t A man is riding a horse. \t 0.2474\n"
     ]
    }
   ],
   "source": [
    "#Encode all sentences\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Compute cosine similarity between all pairs\n",
    "cos_sim = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "#Add all pairs to a list with their cosine similarity score\n",
    "all_sentence_combinations = []\n",
    "for i in range(len(cos_sim)-1):\n",
    "    for j in range(i+1, len(cos_sim)):\n",
    "        all_sentence_combinations.append([cos_sim[i][j], i, j])\n",
    "\n",
    "#Sort list by the highest cosine similarity score\n",
    "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "print(\"Top-5 most similar pairs:\")\n",
    "for score, i, j in all_sentence_combinations[0:5]:\n",
    "    print(\"{} \\t {} \\t {:.4f}\".format(sentences[i], sentences[j], cos_sim[i][j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.2838\n",
      "A man is playing guitar \t\t A woman watches TV \t\t Score: -0.0327\n",
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.8939\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Two lists of sentences\n",
    "sentences1 = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'The new movie is awesome']\n",
    "\n",
    "sentences2 = ['The dog plays in the garden',\n",
    "              'A woman watches TV',\n",
    "              'The new movie is so great']\n",
    "\n",
    "#Compute embedding for both lists\n",
    "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarities\n",
    "cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "\n",
    "#Output the pairs with their score\n",
    "for i in range(len(sentences1)):\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine similarity: 0.3689099848270416\n",
      "Overall Similarity Percentage: 68.45\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "doc1_sentences = []\n",
    "doc1_text = ''\n",
    "\n",
    "with open ('document1.txt') as f:\n",
    "    doc1_text = f.read()\n",
    "    tokens = sent_tokenize(doc1_text)\n",
    "    for line in tokens:\n",
    "        doc1_sentences.append(line)\n",
    "\n",
    "doc2_sentences = []\n",
    "doc2_text = ''\n",
    "\n",
    "with open ('document2.txt') as f:\n",
    "    doc2_text = f.read()\n",
    "    tokens = sent_tokenize(f.read())\n",
    "    for line in tokens:\n",
    "        doc2_sentences.append(line)\n",
    "          \n",
    "\n",
    "#Compute embedding for both lists of sentences\n",
    "# embeddings1 = model.encode(doc1_sentences, convert_to_tensor=True)\n",
    "# embeddings2 = model.encode(doc2_sentences, convert_to_tensor=True)\n",
    "\n",
    "#Compute embedding for both texts\n",
    "embeddings1 = model.encode(doc1_text, convert_to_tensor=True)\n",
    "embeddings2 = model.encode(doc2_text, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarities\n",
    "# cosine_scores = util.cos_sim(embeddings1, embeddings2)\n",
    "cos_score = util.pytorch_cos_sim(embeddings1, embeddings2).item()\n",
    "# print(\"Cosine similarity Array:\", cosine_scores)\n",
    "print(\"Cosine similarity:\", cos_score)\n",
    "# print(\"Length of cosine similarity:\", len(cosine_scores))\n",
    "\n",
    "# # Convert cosine similarity to percentage similarity\n",
    "# percentage_similarity = 100 * (1 + cosine_scores) / 2\n",
    "\n",
    "# # Print the percentage similarity\n",
    "# print(\"Percentage similarity:\", percentage_similarity)\n",
    "\n",
    "\n",
    "# Compute average similarity\n",
    "# average_similarity = torch.mean(cosine_scores).item()\n",
    "\n",
    "# Convert average cosine similarity to percentage similarity\n",
    "# overall_similarity_percentage = (1 + average_similarity) / 2 * 100\n",
    "overall_similarity_percentage = (1 + cos_score) / 2 * 100\n",
    "\n",
    "# Print the overall similarity percentage rounded to 2 decimal places\n",
    "print(\"Overall Similarity Percentage:\", round(overall_similarity_percentage, 2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
